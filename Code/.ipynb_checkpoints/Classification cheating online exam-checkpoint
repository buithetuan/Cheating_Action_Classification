{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN9bEwHiOQLpc8kEyCnKLoO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"id":"gwPsW5N8jgp_","colab":{"base_uri":"https://localhost:8080/","height":380},"executionInfo":{"status":"error","timestamp":1697171198096,"user_tz":-420,"elapsed":300,"user":{"displayName":"Bui The Tuan K17 HL","userId":"16051057934612569164"}},"outputId":"db507b95-e1b0-4df8-8130-3f95dc5dff3e"},"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-14c6eae86cba>\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m#   4 - Full connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#128 is experimentation based no rules for that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/dtensor/utils.py\u001b[0m in \u001b[0;36m_wrap_function\u001b[0;34m(layer_instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0mlayout_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvariable_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_layout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0minit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_instance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m# Inject the layout parameter after the invocation of __init__()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Dense.__init__() missing 1 required positional argument: 'units'"]}],"source":["# Importing the Keras libraries and packages\n","from keras.models import Sequential\n","from keras.layers import Convolution2D#since we are dealing with images we use convulational 2-d in case of videos we use 3-d\n","from keras.layers import MaxPooling2D\n","from keras.layers import Flatten#flattening: to convert large feature map into a vector of inputs for our cnn\n","from keras.layers import Dense#used to add fullly connected layers in an ann\n","\n","# Initialising the CNN\n","classifier = Sequential()\n","\n","# 1 - Convolution\n","classifier.add(Convolution2D(32, 3, 3, input_shape = (256, 256, 3), activation = 'relu'))#32-no. of filters(feature maps we are using),3-rows feasture map,3-columns of feature map,256-size of input image 256X256 is the dimension of 2-d image in each channel 3-no. of channels for colored images we have 3 channels(RGB) and for B&W image we have only one channel since we are using tensorflow backend so our input sequence is (256,256,3) but for theano backend our input sequence will be (3,256,256)\n","\n","#   2 - Pooling\n","#we apply max pooling   to reduce the size of our feature map and therefore to reduce the number of nodes in future fully connected layers and this will reduce complexity and time of execution but without loosing the performance.\n","#because we are keeping track of the parts of the image that\n","#contain the high numbers corresponding to where the feature detectors detected some specific features\n","#in the input image.\n","#So we don't lose the spatial structure information and therefore we don't lose the performance of the\n","#model.\n","#But at the same time we manage to reduce the time complexity and we make it less compute intensive.\n","classifier.add(MaxPooling2D(pool_size = (2, 2)))\n","\n","# Adding a second convolutional layer\n","#this is done in the last   in order to improve the accuracy that we are getting from just one layer and also to decrease the overfitting problem.\n","#here we are not giving input_shape = (256, 256, 3) parameter because keras already knows that the input to this layer will be the output of previous two layers.\n","#input to this layer is the max_pool matrix that we obtained from previous layers\n","classifier.add(Convolution2D(32, 3, 3, activation = 'relu'))\n","classifier.add(MaxPooling2D(pool_size = (2, 2)))\n","classifier.add(Convolution2D(32, 3, 3, activation = 'relu'))\n","classifier.add(MaxPooling2D(pool_size = (2, 2)))\n","#   3 - Flattening\n","\n","classifier.add(Flatten())\n","\n","#   4 - Full connection\n","classifier.add(Dense(output_dim = 128, activation = 'relu')) #128 is experimentation based no rules for that\n","classifier.add(Dense(output_dim = 1, activation = 'sigmoid'))\n","\n","# Compiling the CNN\n","classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","train_datagen = ImageDataGenerator(rescale = 1./255,\n","                                   shear_range = 0.2,\n","                                   zoom_range = 0.2,\n","                                   horizontal_flip = True)\n","#rescale is for feature scaling(since pixel values range from 0-255 so we divide it by 255 to get the values in range of (0,1))\n","#above part is for image augmentation\n","#shear means that we are shifting each pixel of our image by some fixed proportion\n","test_datagen = ImageDataGenerator(rescale = 1./255)\n","\n","training_set = train_datagen.flow_from_directory('Data/total_dataset/train',\n","                                                 target_size = (256, 256),\n","                                                 batch_size = 5,\n","                                                 class_mode = 'binary')\n","#input_shape = (256, 256, 3) so target image size is also 256x256\n","test_set = test_datagen.flow_from_directory('Data/total_dataset/test',\n","                                            target_size = (256, 256),\n","                                            batch_size = 1,\n","                                            class_mode = 'binary')\n","\n","classifier.fit_generator(training_set,\n","                         samples_per_epoch = 290,\n","                         nb_epoch = 15,\n","                         validation_data = test_set,\n","                         nb_val_samples = 32)\n","\n","\n","#below is code for Validation\n","from keras.preprocessing import image\n","import numpy as np\n","string1='dataset/invi_validation/Validation_image ('\n","a=1\n","training_set.class_indices\n","for i in range(12):\n","    string2 = string1 + str(a) + ').jpg'\n","    img = image.load_img(string2, target_size = (256, 256))\n","    test_image = image.img_to_array(img)\n","    test_image = np.expand_dims(test_image, axis = 0)\n","    result = np.round(np.clip(classifier.predict(test_image), 0, 1)).astype(bool)\n","    if result == False :\n","        print(\"Image\"+str(a)+\"is Cheating\")\n","    else :\n","        print(\"Image\"+str(a)+\"is Not Cheating\")\n","    a=a+1"]}]}